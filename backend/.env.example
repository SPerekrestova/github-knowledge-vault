# LLM Provider Configuration
# Choose: "openrouter", "anthropic", or "openai"
LLM_PROVIDER=openrouter

# OpenRouter API Key (Primary)
# Get your key at: https://openrouter.ai/keys
OPENROUTER_API_KEY=sk-or-v1-your_key_here

# Anthropic API Key (Optional fallback)
# ANTHROPIC_API_KEY=sk-ant-your_key_here

# Model Selection
# OpenRouter format: "openrouter/provider/model"
#
# Free models (RECOMMENDED to start):
#   openrouter/meta-llama/llama-3.3-70b-instruct - Best overall (70B params, 128K context)
#   openrouter/qwen/qwen-coder-turbo - Best for coding (262K context)
#   openrouter/deepseek/deepseek-r1 - Best for reasoning
#
# Paid models via OpenRouter:
#   openrouter/anthropic/claude-3.5-sonnet - Claude via OpenRouter ($3/M tokens)
#   openrouter/openai/gpt-4o - GPT-4 via OpenRouter ($2.5-10/M tokens)
MODEL_NAME=openrouter/meta-llama/llama-3.3-70b-instruct

# Legacy Claude model (used when LLM_PROVIDER=anthropic)
CLAUDE_MODEL=claude-sonnet-4-20250514

# Maximum tokens for responses
MAX_TOKENS=4096

# MCP Server Configuration
# URL of the MCP server (default: http://mcp-server:3000)
MCP_SERVER_URL=http://mcp-server:3000

# Timeout for MCP requests in seconds (default: 30)
MCP_TIMEOUT=30

# CORS Configuration
# Comma-separated list of allowed origins
# CORS_ORIGINS=http://localhost:5173,http://localhost:3000
